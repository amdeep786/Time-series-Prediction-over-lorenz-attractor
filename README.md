# Time-series-Prediction-over-lorenz-attractor

A Reservoir Computing Model (or Echo-State-Network) is a special type of recurrent neural networks. The name giving reservoir is a set of sparsely connected neurons or nodes with the special property, in contrary to backpropagation, that the weights (and biases) between the nodes are not trainable parameteres and that the neurons are not organized in (hidden) layers. The weights that connect the input  with the reservoir $A$ as well as the reservoir itself are randomly generated, which leads to the neccesity of training multiple RCMs and averaging their results to evaluate the performance. Only the weights that connect the reservoir to the output layer are trainable parameteres, which makes the training process very fast.

The dot product of the input time series and the input weights gives the states vector. The states of a future time step are then calculated by a summation of a linear and a nonlinear function. The leakage rate $\alpha$ controls which term is dominant and can also be seen as short-term memory. The output weight matrix converts the states back into a time series and is optimized to by minimizing a quadratic cost function. A regularization term is used to reduce overfitting. Its prefactor is also called ridge regression parameter and controlls the aggressivity of the regularization.
